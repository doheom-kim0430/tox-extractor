import streamlit as st
import pandas as pd
from openpyxl import load_workbook
from openpyxl.styles import Alignment, Border, Side, Font
import io
import os
import re

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í˜ì´ì§€ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="ë…ì„±ì •ë³´ ìë™ ì¶”ì¶œ ì‹œìŠ¤í…œ", layout="wide")
st.title("ğŸ§ª í™”í•™ë¬¼ì§ˆ ë…ì„±ì •ë³´ ìë™ ì¶”ì¶œ ì„œë¹„ìŠ¤")
st.info("ë‚´ë¶€ì‹ë³„ìë¥¼ ì…ë ¥í•˜ë©´ DBì—ì„œ ë…ì„±ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ ì—‘ì…€ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.")

DB_FILENAME = "ìœ í•´ì„±ë¯¸í™•ì¸ë¬¼ì§ˆ 12ì¢… DB.xlsx"
TPL_SINGLE  = "ê°œë³„ë¬¼ì§ˆ ì¶”ì¶œ í…œí”Œë¦¿.xlsx"
TPL_MULTI   = "ë‹¤ì¤‘ë¬¼ì§ˆ ì¶”ì¶œ í…œí”Œë¦¿.xlsx"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê°œë³„ë¬¼ì§ˆ í…œí”Œë¦¿ ì—´ ë§¤í•‘ (í…œí”Œë¦¿ ì§ì ‘ ë¶„ì„ ê¸°ë°˜)
# D=4  E=5  F=6  G=7  H=8  I=9  J=10  K=11  L=12  M=13  N=14  O=15  P=16  Q=17
# ECHA US   Pub  Kre  í™˜ê²½  TB_RA TB_Q  Dan   VEGA  Epi   HAZ   Pro   Vega  Chemi
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SINGLE_COLS = {
    'ECHA CHEM':            4,   # D
    'US DashBoard':         5,   # E
    'Pubchem':              6,   # F
    'K-reach':              7,   # G
    'í™˜ê²½ë¶€ìœ í•´ì„±ì‹¬ì‚¬ê²°ê³¼': 8,   # H
    'TB_RA':                9,   # I  QSAR Toolbox Read-across
    'TB_QSAR':             10,   # J  QSAR Toolbox QSAR
    'Danish QSAR':         11,   # K
    'VEGA_QSAR':           12,   # L  VEGA QSAR
    'Epi suite':           13,   # M
    'HAZMAP':              14,   # N
    'Protox 3.0':          15,   # O
    'VEGA_AI':             16,   # P  VEGA AI-based QSAR
    'Cheminfomatics':      17,   # Q
}

# ê°œë³„ë¬¼ì§ˆ ìœ í•´ì„± ë°ì´í„° í–‰ (row 12~21)
SINGLE_CAT_ROWS = {
    'ê¸‰ì„±ê²½êµ¬ë…ì„±':                        12,
    'ê¸‰ì„±í¡ì…ë…ì„±':                        13,
    'í”¼ë¶€ë¶€ì‹ì„±/ìê·¹ì„±':                   14,
    'ë³µê·€ëŒì—°ë³€ì´':                        15,
    'í¬ìœ ë¥˜ ë°°ì–‘ì„¸í¬ë¥¼ ì´ìš©í•œ ì—¼ìƒ‰ì²´ì´ìƒ': 16,
    'ì†Œí•µì‹œí—˜':                            17,
    'ì–´ë¥˜ê¸‰ì„±ë…ì„±':                        18,
    'ë¬¼ë²¼ë£©ê¸‰ì„±ë…ì„±':                      19,
    'ë‹´ìˆ˜ì¡°ë¥˜ìƒì¥ì €í•´':                    20,
    'ì´ë¶„í•´ì„±':                            21,
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë‹¤ì¤‘ë¬¼ì§ˆ í…œí”Œë¦¿ ì—´ ë§¤í•‘ (í…œí”Œë¦¿ ì§ì ‘ ë¶„ì„ ê¸°ë°˜)
# F=6  G=7  H=8  I=9  J=10  K=11  L=12  M=13  N=14  O=15  P=16  Q=17  R=18  S=19
# ECHA US   Pub  Kre  í™˜ê²½  TB_RA  TB_Q  Dan   VEGA  Epi   HAZ   Pro   Vega  Chemi
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MULTI_COLS = {
    'ECHA CHEM':            6,   # F
    'US DashBoard':         7,   # G
    'Pubchem':              8,   # H
    'K-reach':              9,   # I
    'í™˜ê²½ë¶€ìœ í•´ì„±ì‹¬ì‚¬ê²°ê³¼': 10,   # J
    'TB_RA':               11,   # K  QSAR Toolbox Read-across
    'TB_QSAR':             12,   # L  QSAR Toolbox QSAR
    'Danish QSAR':         13,   # M
    'VEGA_QSAR':           14,   # N  VEGA QSAR
    'Epi suite':           15,   # O
    'HAZMAP':              16,   # P
    'Protox 3.0':          17,   # Q
    'VEGA_AI':             18,   # R  VEGA AI-based QSAR
    'Cheminfomatics':      19,   # S
}

# ë‹¤ì¤‘ë¬¼ì§ˆ ë¸”ë¡ í—¤ë”í–‰ (row2=ë¸”ë¡1, row15=ë¸”ë¡2)
MULTI_BLOCK_HEADERS = [2, 15]

# ìœ í•´ì„± í•­ëª© row offset (í—¤ë”í–‰ ê¸°ì¤€)
MULTI_CAT_OFFSETS = {
    'ê¸‰ì„±ê²½êµ¬ë…ì„±':                         2,   # ë¸”ë¡1:row4,  ë¸”ë¡2:row17
    'ê¸‰ì„±í¡ì…ë…ì„±':                         3,   # ë¸”ë¡1:row5,  ë¸”ë¡2:row18
    'í”¼ë¶€ë¶€ì‹ì„±/ìê·¹ì„±':                    4,   # ë¸”ë¡1:row6,  ë¸”ë¡2:row19
    'ë³µê·€ëŒì—°ë³€ì´':                         5,   # ë¸”ë¡1:row7,  ë¸”ë¡2:row20
    'í¬ìœ ë¥˜ ë°°ì–‘ì„¸í¬ë¥¼ ì´ìš©í•œ ì—¼ìƒ‰ì²´ì´ìƒ':  6,   # ë¸”ë¡1:row8,  ë¸”ë¡2:row21
    'ì†Œí•µì‹œí—˜':                             7,   # ë¸”ë¡1:row9,  ë¸”ë¡2:row22
    'ì–´ë¥˜ê¸‰ì„±ë…ì„±':                         8,   # ë¸”ë¡1:row10, ë¸”ë¡2:row23
    'ë¬¼ë²¼ë£©ê¸‰ì„±ë…ì„±':                       9,   # ë¸”ë¡1:row11, ë¸”ë¡2:row24
    'ë‹´ìˆ˜ì¡°ë¥˜ìƒì¥ì €í•´':                    10,   # ë¸”ë¡1:row12, ë¸”ë¡2:row25
    'ì´ë¶„í•´ì„±':                            11,   # ë¸”ë¡1:row13, ë¸”ë¡2:row26
}

# ë¬¼ì§ˆì •ë³´ offset (í—¤ë”í–‰ ê¸°ì¤€, INFO_COL=B=2)
MULTI_INFO_OFFSETS = {
    'ë‚´ë¶€ì‹ë³„ì': 1,   # ë¸”ë¡1:row3,  ë¸”ë¡2:row16
    'CAS No.':    3,   # ë¸”ë¡1:row5,  ë¸”ë¡2:row18
    'ë¬¼ì§ˆëª…':     5,   # ë¸”ë¡1:row7,  ë¸”ë¡2:row20
    'ë¶„ìì‹':     7,   # ë¸”ë¡1:row9,  ë¸”ë¡2:row22
    'ë¶„ìëŸ‰':     9,   # ë¸”ë¡1:row11, ë¸”ë¡2:row24
}
MULTI_INFO_COL = 2  # Bì—´


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê³µí†µ ìœ í‹¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def write_safe(ws, row, col, value):
    """ë³‘í•© ì…€ í¬í•¨ ì•ˆì „ ì…ë ¥"""
    cell = ws.cell(row=row, column=col)
    for merged in ws.merged_cells.ranges:
        if cell.coordinate in merged:
            ws.cell(row=merged.min_row, column=merged.min_col).value = value
            return
    cell.value = value


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# VEGA ìš°ì„ ìˆœìœ„ ë¡œì§
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
VEGA_PRIORITY = ["EXPERIMENTAL value", "GOOD reliability", "MODERATE reliability", "LOW reliability"]

def get_best_vega(df):
    if df.empty:
        return None
    temp = df.copy()
    def rank(v):
        v = str(v)
        for i, label in enumerate(VEGA_PRIORITY):
            if label.lower() in v.lower():
                return len(VEGA_PRIORITY) - i
        return 0
    def score(v):
        m = re.search(r'\(([0-9.]+)\)', str(v))
        return float(m.group(1)) if m else 0.0
    temp['_rank']  = temp['Domain status'].apply(rank)
    temp['_score'] = temp['Domain status'].apply(score)
    return temp.sort_values(['_rank','_score'], ascending=[False,False]).iloc[0]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê³µí†µ í¬ë§· í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def apply_priority_exp(df, cat):
    """ì‹¤í—˜ê°’ ìš°ì„ ìˆœìœ„ ì •ë ¬"""
    if len(df) <= 1:
        return df.iloc[0]
    temp = df.copy()
    if cat == "ê¸‰ì„±ê²½êµ¬ë…ì„±":
        temp['p1'] = (temp['Endpoint(í‘œì¤€)'] == 'LD50').astype(int)
        temp['p2'] = (temp['ì‹œí—˜ì¢…(í‘œì¤€)'] == 'Rat').astype(int)
        temp['p3'] = temp['ì‹œí—˜ì§€ì¹¨'].astype(str).str.contains('401', na=False).astype(int)
        temp = temp.sort_values(['p1','p2','p3','Result'], ascending=[False,False,False,True])
    elif cat == "ê¸‰ì„±í¡ì…ë…ì„±":
        temp['p1'] = (temp['Endpoint(í‘œì¤€)'] == 'LC50').astype(int)
        temp['p2'] = (temp['ì‹œí—˜ì¢…(í‘œì¤€)'] == 'Rat').astype(int)
        temp['p3'] = (temp['Duration(í‘œì¤€)'] == '4 h').astype(int)
        temp['p4'] = temp['ì‹œí—˜ì§€ì¹¨'].astype(str).str.contains('403', na=False).astype(int)
        temp = temp.sort_values(['p1','p2','p3','p4','Result'], ascending=[False,False,False,False,True])
    elif cat == "ì–´ë¥˜ê¸‰ì„±ë…ì„±":
        temp['p1'] = (temp['Endpoint(í‘œì¤€)'] == 'LC50').astype(int)
        temp['p2'] = temp['ì‹œí—˜ì¢…(í‘œì¤€)'].isin(['Fathead minnow','Zebrafish','Rainbow trout']).astype(int)
        temp['p3'] = (temp['Duration(í‘œì¤€)'] == '96 h').astype(int)
        temp['p4'] = temp['ì‹œí—˜ì§€ì¹¨'].astype(str).str.contains('203', na=False).astype(int)
        temp = temp.sort_values(['p1','p2','p3','p4','Result'], ascending=[False,False,False,False,True])
    elif cat == "ë¬¼ë²¼ë£©ê¸‰ì„±ë…ì„±":
        temp['p1'] = (temp['Endpoint(í‘œì¤€)'] == 'EC50').astype(int)
        temp['p2'] = (temp['ì‹œí—˜ì¢…(í‘œì¤€)'] == 'Daphnia magna').astype(int)
        temp['p3'] = (temp['Duration(í‘œì¤€)'] == '48 h').astype(int)
        temp['p4'] = temp['ì‹œí—˜ì§€ì¹¨'].astype(str).str.contains('202', na=False).astype(int)
        temp = temp.sort_values(['p1','p2','p3','p4','Result'], ascending=[False,False,False,False,True])
    elif cat == "ë‹´ìˆ˜ì¡°ë¥˜ìƒì¥ì €í•´":
        temp['p1'] = (temp['Endpoint(í‘œì¤€)'] == 'EC50').astype(int)
        temp['p2'] = temp['ì‹œí—˜ì¢…(í‘œì¤€)'].isin(['P. subcapitata','D. subspicatus']).astype(int)
        temp['p3'] = (temp['Duration(í‘œì¤€)'] == '72 h').astype(int)
        temp['p4'] = temp['ì‹œí—˜ì§€ì¹¨'].astype(str).str.contains('201', na=False).astype(int)
        temp = temp.sort_values(['p1','p2','p3','p4','Result'], ascending=[False,False,False,False,True])
    return temp.iloc[0]


def apply_priority_qsar_danish(df, cat, exp_species=None):
    """Danish QSAR ìš°ì„ ìˆœìœ„ ì •ë ¬"""
    if len(df) <= 1:
        return df.iloc[0]
    temp = df.copy()
    model_map = {
        "ê¸‰ì„±ê²½êµ¬ë…ì„±":      "Acute toxicity in Rat, Oral - Danish QSAR DB ACDLabs model (v1.0)",
        "ë‹´ìˆ˜ì¡°ë¥˜ìƒì¥ì €í•´":  "Pseudokirchneriella subcapitata 72h EC50 - Danish QSAR DB battery model (v1.0)",
        "ë¬¼ë²¼ë£©ê¸‰ì„±ë…ì„±":    "Daphnia magna 48h EC50 - Danish QSAR DB battery model (v1.0)",
        "ë³µê·€ëŒì—°ë³€ì´":      "Ames test in S. typhimurium (in vitro) - Danish QSAR DB battery model (v1.0)",
        "ì†Œí•µì‹œí—˜":          "Micronucleus Test in Mouse Erythrocytes - Danish QSAR DB battery model (v1.0)",
        "ì–´ë¥˜ê¸‰ì„±ë…ì„±":      "Fathead minnow 96h LC50 - Danish QSAR DB battery model (v1.0)",
        "í”¼ë¶€ë¶€ì‹ì„±/ìê·¹ì„±": "BfR skin irritation/corrosion (v1.0)"
    }
    if cat == "í¬ìœ ë¥˜ ë°°ì–‘ì„¸í¬ë¥¼ ì´ìš©í•œ ì—¼ìƒ‰ì²´ì´ìƒ":
        mname = ("Chromosome Aberrations in Chinese Hamster Ovary (CHO) Cells - Danish QSAR DB battery model (v1.0)"
                 if exp_species == "CHO Cells"
                 else "Chromosome Aberrations in Chinese Hamster Lung (CHL) Cells - Danish QSAR DB battery model (v1.0)")
        temp['p_q'] = (temp['ëª¨ë¸ ì¢…ë¥˜ ë° ë²„ì „'] == mname).astype(int)
    elif cat in model_map:
        temp['p_q'] = (temp['ëª¨ë¸ ì¢…ë¥˜ ë° ë²„ì „'] == model_map[cat]).astype(int)
    else:
        temp['p_q'] = 0
    return temp.sort_values('p_q', ascending=False).iloc[0]


def format_exp(row, cat):
    """ì‹¤í—˜ê°’/Read-across í¬ë§·"""
    res = str(row['Result'])
    val_cats = ["ê¸‰ì„±ê²½êµ¬ë…ì„±","ê¸‰ì„±í¡ì…ë…ì„±","ì–´ë¥˜ê¸‰ì„±ë…ì„±","ë¬¼ë²¼ë£©ê¸‰ì„±ë…ì„±","ë‹´ìˆ˜ì¡°ë¥˜ìƒì¥ì €í•´"]
    if cat in val_cats:
        return f"{row['Endpoint(í‘œì¤€)']} = {res} {row['ë‹¨ìœ„']} ({row['ì‹œí—˜ì¢…(í‘œì¤€)']})"
    return res


def format_qsar(row, cat):
    """QSAR í¬ë§· (Out of domain ì²˜ë¦¬ í¬í•¨)"""
    res = str(row['Result'])
    if str(row.get('Domain status','')) == "Out of domain":
        res += " (Out of domain)"
    val_cats = ["ê¸‰ì„±ê²½êµ¬ë…ì„±","ê¸‰ì„±í¡ì…ë…ì„±","ì–´ë¥˜ê¸‰ì„±ë…ì„±","ë¬¼ë²¼ë£©ê¸‰ì„±ë…ì„±","ë‹´ìˆ˜ì¡°ë¥˜ìƒì¥ì €í•´"]
    if cat in val_cats:
        return f"{row['Endpoint(í‘œì¤€)']} = {res} {row['ë‹¨ìœ„']} ({row['ì‹œí—˜ì¢…(í‘œì¤€)']})"
    return res


def format_multi_standard(row, cat):
    """ë‹¤ì¤‘ ì¶”ì¶œìš© í¬ë§·"""
    res  = str(row['Result'])
    ep   = row.get('Endpoint') if pd.notna(row.get('Endpoint')) else (row.get('Endpoint(í‘œì¤€)','Unknown') or 'Unknown')
    sp   = row.get('ì‹œí—˜ì¢…(í‘œì¤€)') if pd.notna(row.get('ì‹œí—˜ì¢…(í‘œì¤€)')) else (row.get('ì‹œí—˜ì¢…','Unknown') or 'Unknown')
    unit = row.get('ë‹¨ìœ„','') if pd.notna(row.get('ë‹¨ìœ„')) else ""
    if "(Out of domain)" not in res and pd.notna(row.get('Domain status')) and str(row.get('Domain status')) == "Out of domain":
        res += " (Out of domain)"
    val_cats = ["ê¸‰ì„±ê²½êµ¬ë…ì„±","ê¸‰ì„±í¡ì…ë…ì„±","ì–´ë¥˜ê¸‰ì„±ë…ì„±","ë¬¼ë²¼ë£©ê¸‰ì„±ë…ì„±","ë‹´ìˆ˜ì¡°ë¥˜ìƒì¥ì €í•´"]
    if cat in val_cats:
        return f"{ep} = {res} {unit} ({sp})"
    return res


def format_biodeg(row):
    """ì´ë¶„í•´ì„± í¬ë§·"""
    if row['ì¶œì²˜'] in ['í™˜ê²½ë¶€ìœ í•´ì„±ì‹¬ì‚¬ê²°ê³¼','K-reach'] or \
       (row['ê²°ê³¼ë„ì¶œë°©ë²•'] == 'QSAR' and row['ì¶œì²˜'] == 'Epi suite'):
        return str(row['Result'])
    try:
        val = float(row['Result'])
        ep  = str(row['Endpoint']).lower()
        threshold = 70 if 'doc' in ep else 60
        status = "positive(ì´ë¶„í•´ì„±)" if val >= threshold else "negative(ë‚œë¶„í•´ì„±)"
        return f"{status} - {row['Endpoint']} = {row['Result']} {row['ë‹¨ìœ„']}"
    except:
        return str(row['Result'])


def filter_skin_exp(df):
    """í”¼ë¶€ë¶€ì‹ì„± ì‹¤í—˜ê°’: Positive/Negative ì¤‘ Rabbit ìš°ì„ """
    temp = df[df['Result'].astype(str).str.lower().isin(['positive','negative'])]
    if not temp.empty:
        rabbit = temp[temp['ì‹œí—˜ì¢…(í‘œì¤€)'].astype(str).str.contains('Rabbit', case=False, na=False)]
        return rabbit.iloc[0] if not rabbit.empty else temp.iloc[0]
    return None


def get_best_multi(df, cat):
    """ë‹¤ì¤‘ ì¶”ì¶œìš© ìš°ì„ ìˆœìœ„ (VEGA ì œì™¸ ì¼ë°˜)"""
    if df.empty:
        return None
    temp = df.copy()
    temp['result_num'] = pd.to_numeric(temp['Result'], errors='coerce').fillna(999999)
    if cat == 'ì´ë¶„í•´ì„±':
        def gl(v):
            v = str(v).upper()
            return 2 if 'OECD' in v else (1 if v not in ['-','','NAN'] else 0)
        temp['gl'] = temp['ì‹œí—˜ì§€ì¹¨'].apply(gl)
        return temp.sort_values(['gl','result_num'], ascending=[False,False]).iloc[0]
    if cat in ["ê¸‰ì„±ê²½êµ¬ë…ì„±","ê¸‰ì„±í¡ì…ë…ì„±","ì–´ë¥˜ê¸‰ì„±ë…ì„±","ë¬¼ë²¼ë£©ê¸‰ì„±ë…ì„±","ë‹´ìˆ˜ì¡°ë¥˜ìƒì¥ì €í•´"]:
        tep = "LD50" if "ê²½êµ¬" in cat else ("LC50" if "ì–´ë¥˜" in cat or "í¡ì…" in cat else "EC50")
        temp['ep_s'] = (
            temp['Endpoint'].astype(str).str.contains(tep, case=False, na=False) |
            temp['Endpoint(í‘œì¤€)'].astype(str).str.contains(tep, case=False, na=False)
        ).astype(int) * 10
        tsp = ("Rat" if "ê²½êµ¬" in cat or "í¡ì…" in cat else
               "Fathead minnow" if "ì–´ë¥˜" in cat else
               "Daphnia magna"  if "ë¬¼ë²¼ë£©" in cat else "P. subcapitata")
        temp['sp_s'] = temp['ì‹œí—˜ì¢…(í‘œì¤€)'].astype(str).str.contains(tsp, case=False, na=False).astype(int) * 5
        temp['tot'] = temp['ep_s'] + temp['sp_s']
        return temp.sort_values(['tot','result_num'], ascending=[False,True]).iloc[0]
    return temp.iloc[0]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë‹¨ì¼ ì¶”ì¶œ ì‹¤í–‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def extract_single(target_id, df_mat, df_tox, wb):
    ws = wb.active

    # ë¬¼ì§ˆ ê¸°ë³¸ì •ë³´ (row7: C=ë‚´ë¶€ì‹ë³„ì, D=CAS, E=ë¬¼ì§ˆëª…, F=ë¶„ìì‹, G=ë¶„ìëŸ‰)
    mat_row = df_mat[df_mat['ë‚´ë¶€ì‹ë³„ì'] == target_id]
    if mat_row.empty:
        raise ValueError(f"'{target_id}' ë¬¼ì§ˆì •ë³´ë¥¼ DBì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    t = mat_row.iloc[0]
    write_safe(ws, 7, 3, target_id)
    write_safe(ws, 7, 4, str(t['CAS']))
    write_safe(ws, 7, 5, str(t['ë¬¼ì§ˆëª…']))
    write_safe(ws, 7, 6, str(t['ë¶„ìì‹']))
    write_safe(ws, 7, 7, str(t['ë¶„ìëŸ‰']))

    for cat, data_row in SINGLE_CAT_ROWS.items():
        df_cat = df_tox[(df_tox['ë‚´ë¶€ì‹ë³„ì'] == target_id) & (df_tox['ìœ í•´ì„±í•­ëª©'] == cat)]
        exp_species_found = None

        # â”€â”€ ì‹¤í—˜ê°’ (D~H, col 4~8) â”€â”€
        for src, col in [('ECHA CHEM',4),('US DashBoard',5),('Pubchem',6),('K-reach',7),('í™˜ê²½ë¶€ìœ í•´ì„±ì‹¬ì‚¬ê²°ê³¼',8)]:
            df_s = df_cat[(df_cat['ê²°ê³¼ë„ì¶œë°©ë²•'] == 'ì‹¤í—˜ê°’') & (df_cat['ì¶œì²˜'] == src)]
            if df_s.empty:
                continue
            if cat == 'í”¼ë¶€ë¶€ì‹ì„±/ìê·¹ì„±':
                best = filter_skin_exp(df_s)
            else:
                best = apply_priority_exp(df_s, cat)
            if best is not None:
                ws.cell(row=data_row, column=col).value = format_exp(best, cat)
                if cat == "í¬ìœ ë¥˜ ë°°ì–‘ì„¸í¬ë¥¼ ì´ìš©í•œ ì—¼ìƒ‰ì²´ì´ìƒ":
                    exp_species_found = best['ì‹œí—˜ì¢…(í‘œì¤€)']

        # â”€â”€ QSAR Toolbox Read-across (I=9) â”€â”€
        df_s = df_cat[(df_cat['ê²°ê³¼ë„ì¶œë°©ë²•'] == 'Read-across') & (df_cat['ì¶œì²˜'] == 'QSAR Toolbox v.4.8')]
        if not df_s.empty:
            ws.cell(row=data_row, column=9).value = format_multi_standard(df_s.iloc[0], cat)

        # â”€â”€ QSAR Toolbox QSAR (J=10) â”€â”€
        df_s = df_cat[(df_cat['ê²°ê³¼ë„ì¶œë°©ë²•'] == 'QSAR') & (df_cat['ì¶œì²˜'] == 'QSAR Toolbox v.4.8')]
        if not df_s.empty:
            ws.cell(row=data_row, column=10).value = format_qsar(df_s.iloc[0], cat)

        # â”€â”€ Danish QSAR (K=11) â”€â”€
        df_s = df_cat[(df_cat['ê²°ê³¼ë„ì¶œë°©ë²•'] == 'QSAR') & (df_cat['ì¶œì²˜'] == 'Danish QSAR')]
        if not df_s.empty:
            best = apply_priority_qsar_danish(df_s, cat, exp_species_found)
            ws.cell(row=data_row, column=11).value = format_qsar(best, cat)

        # â”€â”€ VEGA QSAR (L=12) â”€â”€
        df_s = df_cat[(df_cat['ì¶œì²˜'] == 'VEGA') & (df_cat['ê²°ê³¼ë„ì¶œë°©ë²•'] == 'QSAR')]
        if not df_s.empty:
            best = get_best_vega(df_s)
            if best is not None:
                ws.cell(row=data_row, column=12).value = format_qsar(best, cat)

        # â”€â”€ Epi suite (M=13) â”€â”€
        df_s = df_cat[(df_cat['ê²°ê³¼ë„ì¶œë°©ë²•'] == 'QSAR') & (df_cat['ì¶œì²˜'] == 'Epi suite')]
        if not df_s.empty:
            if cat == 'ì´ë¶„í•´ì„±':
                ws.cell(row=data_row, column=13).value = format_biodeg(df_s.iloc[0])
            else:
                ws.cell(row=data_row, column=13).value = format_qsar(df_s.iloc[0], cat)

        # â”€â”€ HAZMAP (N=14) â”€â”€
        df_s = df_cat[(df_cat['ê²°ê³¼ë„ì¶œë°©ë²•'] == 'AI-based QSAR') & (df_cat['ì¶œì²˜'] == 'HAZMAP')]
        if not df_s.empty:
            ws.cell(row=data_row, column=14).value = str(df_s.iloc[0]['Result'])

        # â”€â”€ Protox 3.0 (O=15) â”€â”€
        df_s = df_cat[(df_cat['ê²°ê³¼ë„ì¶œë°©ë²•'] == 'AI-based QSAR') & (df_cat['ì¶œì²˜'] == 'Protox 3.0')]
        if not df_s.empty:
            ws.cell(row=data_row, column=15).value = str(df_s.iloc[0]['Result'])

        # â”€â”€ VEGA AI-based QSAR (P=16) â”€â”€
        df_s = df_cat[(df_cat['ì¶œì²˜'] == 'VEGA') & (df_cat['ê²°ê³¼ë„ì¶œë°©ë²•'] == 'AI-based QSAR')]
        if not df_s.empty:
            best = get_best_vega(df_s)
            if best is not None:
                ws.cell(row=data_row, column=16).value = str(best['Result'])

        # â”€â”€ Cheminfomatics (Q=17) â”€â”€
        df_s = df_cat[(df_cat['ê²°ê³¼ë„ì¶œë°©ë²•'] == 'AI-based QSAR') & (df_cat['ì¶œì²˜'] == 'Cheminfomatics')]
        if not df_s.empty:
            ws.cell(row=data_row, column=17).value = str(df_s.iloc[0]['Result'])

    # ìŠ¤íƒ€ì¼
    thin = Border(left=Side(style='thin'), right=Side(style='thin'),
                  top=Side(style='thin'),  bottom=Side(style='thin'))
    for rng in [ws['C7:G7'], ws['B11:Q21']]:
        for row in rng:
            for cell in row:
                cell.border    = thin
                cell.alignment = Alignment(horizontal='center', vertical='center', wrap_text=True)
                cell.font      = Font(name='ë§‘ì€ ê³ ë”•', size=9)
    col_widths = {'B':12,'C':15,'D':22,'E':25,'F':12,'G':12,'H':22,
                  'I':18,'J':20,'K':20,'L':20,'M':20,'N':15,'O':15,'P':15,'Q':15}
    for col, w in col_widths.items():
        ws.column_dimensions[col].width = w
    for i in range(12, 22):
        ws.row_dimensions[i].height = 45


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë‹¤ì¤‘ ì¶”ì¶œ ì‹¤í–‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def extract_multi(tid1, tid2, df_mat, df_tox, wb):
    ws = wb.active
    ws.title = f"{tid1} ë° {tid2}"

    # ë°ì´í„° ì…€ ì´ˆê¸°í™”
    for hdr in MULTI_BLOCK_HEADERS:
        for offset in MULTI_INFO_OFFSETS.values():
            ws.cell(row=hdr + offset, column=MULTI_INFO_COL).value = None
        for offset in MULTI_CAT_OFFSETS.values():
            for col in range(6, 20):
                ws.cell(row=hdr + offset, column=col).value = None

    for tid, hdr_row in zip([tid1, tid2], MULTI_BLOCK_HEADERS):
        mat_row = df_mat[df_mat['ë‚´ë¶€ì‹ë³„ì'] == tid]
        if mat_row.empty:
            raise ValueError(f"'{tid}' ë¬¼ì§ˆì •ë³´ë¥¼ DBì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        t = mat_row.iloc[0]

        # ë¬¼ì§ˆ ê¸°ë³¸ì •ë³´
        for label, offset in MULTI_INFO_OFFSETS.items():
            val = {
                'ë‚´ë¶€ì‹ë³„ì': tid,
                'CAS No.':    str(t['CAS']),
                'ë¬¼ì§ˆëª…':     str(t['ë¬¼ì§ˆëª…']),
                'ë¶„ìì‹':     str(t['ë¶„ìì‹']),
                'ë¶„ìëŸ‰':     f"{t['ë¶„ìëŸ‰']} g/mol",
            }[label]
            write_safe(ws, hdr_row + offset, MULTI_INFO_COL, val)

        df_sub = df_tox[df_tox['ë‚´ë¶€ì‹ë³„ì'] == tid]

        for cat, cat_offset in MULTI_CAT_OFFSETS.items():
            data_row = hdr_row + cat_offset
            df_cat   = df_sub[df_sub['ìœ í•´ì„±í•­ëª©'] == cat]

            # â”€â”€ ì‹¤í—˜ê°’ (F~J, col 6~10) â”€â”€
            for src, col in [('ECHA CHEM',6),('US DashBoard',7),('Pubchem',8),('K-reach',9),('í™˜ê²½ë¶€ìœ í•´ì„±ì‹¬ì‚¬ê²°ê³¼',10)]:
                df_s = df_cat[(df_cat['ê²°ê³¼ë„ì¶œë°©ë²•'] == 'ì‹¤í—˜ê°’') & (df_cat['ì¶œì²˜'] == src)]
                if df_s.empty:
                    continue
                if cat == 'í”¼ë¶€ë¶€ì‹ì„±/ìê·¹ì„±':
                    best = filter_skin_exp(df_s)
                else:
                    best = apply_priority_exp(df_s, cat)
                if best is not None:
                    write_safe(ws, data_row, col, format_multi_standard(best, cat))

            # â”€â”€ QSAR Toolbox Read-across (K=11) â”€â”€
            df_s = df_cat[
                df_cat['ì¶œì²˜'].astype(str).str.contains('QSAR Toolbox', case=False, na=False) &
                df_cat['ê²°ê³¼ë„ì¶œë°©ë²•'].astype(str).str.contains('Read across', case=False, na=False)
            ]
            if not df_s.empty:
                write_safe(ws, data_row, 11, format_multi_standard(df_s.iloc[0], cat))

            # â”€â”€ QSAR Toolbox QSAR (L=12) â”€â”€
            df_s = df_cat[
                df_cat['ì¶œì²˜'].astype(str).str.contains('QSAR Toolbox', case=False, na=False) &
                ~df_cat['ê²°ê³¼ë„ì¶œë°©ë²•'].astype(str).str.contains('Read across', case=False, na=False) &
                (df_cat['ê²°ê³¼ë„ì¶œë°©ë²•'] == 'QSAR')
            ]
            if not df_s.empty:
                write_safe(ws, data_row, 12, format_multi_standard(df_s.iloc[0], cat))

            # â”€â”€ Danish QSAR (M=13) â”€â”€
            df_s = df_cat[(df_cat['ê²°ê³¼ë„ì¶œë°©ë²•'] == 'QSAR') & (df_cat['ì¶œì²˜'] == 'Danish QSAR')]
            if not df_s.empty:
                best = get_best_multi(df_s, cat)
                if best is not None:
                    write_safe(ws, data_row, 13, format_multi_standard(best, cat))

            # â”€â”€ VEGA QSAR (N=14) â”€â”€
            df_s = df_cat[(df_cat['ì¶œì²˜'] == 'VEGA') & (df_cat['ê²°ê³¼ë„ì¶œë°©ë²•'] == 'QSAR')]
            if not df_s.empty:
                best = get_best_vega(df_s)
                if best is not None:
                    write_safe(ws, data_row, 14, format_multi_standard(best, cat))

            # â”€â”€ Epi suite (O=15) â”€â”€
            df_s = df_cat[(df_cat['ê²°ê³¼ë„ì¶œë°©ë²•'] == 'QSAR') & (df_cat['ì¶œì²˜'] == 'Epi suite')]
            if not df_s.empty:
                if cat == 'ì´ë¶„í•´ì„±':
                    write_safe(ws, data_row, 15, format_biodeg(df_s.iloc[0]))
                else:
                    write_safe(ws, data_row, 15, format_multi_standard(df_s.iloc[0], cat))

            # â”€â”€ HAZMAP (P=16) â”€â”€
            df_s = df_cat[(df_cat['ê²°ê³¼ë„ì¶œë°©ë²•'] == 'AI-based QSAR') & (df_cat['ì¶œì²˜'] == 'HAZMAP')]
            if not df_s.empty:
                write_safe(ws, data_row, 16, str(df_s.iloc[0]['Result']))

            # â”€â”€ Protox 3.0 (Q=17) â”€â”€
            df_s = df_cat[(df_cat['ê²°ê³¼ë„ì¶œë°©ë²•'] == 'AI-based QSAR') & (df_cat['ì¶œì²˜'] == 'Protox 3.0')]
            if not df_s.empty:
                write_safe(ws, data_row, 17, str(df_s.iloc[0]['Result']))

            # â”€â”€ VEGA AI-based QSAR (R=18) â”€â”€
            df_s = df_cat[(df_cat['ì¶œì²˜'] == 'VEGA') & (df_cat['ê²°ê³¼ë„ì¶œë°©ë²•'] == 'AI-based QSAR')]
            if not df_s.empty:
                best = get_best_vega(df_s)
                if best is not None:
                    write_safe(ws, data_row, 18, str(best['Result']))

            # â”€â”€ Cheminfomatics (S=19) â”€â”€
            df_s = df_cat[(df_cat['ê²°ê³¼ë„ì¶œë°©ë²•'] == 'AI-based QSAR') & (df_cat['ì¶œì²˜'] == 'Cheminfomatics')]
            if not df_s.empty:
                write_safe(ws, data_row, 19, str(df_s.iloc[0]['Result']))

    # ìŠ¤íƒ€ì¼
    thin = Border(left=Side(style='thin'), right=Side(style='thin'),
                  top=Side(style='thin'),  bottom=Side(style='thin'))
    for hdr in MULTI_BLOCK_HEADERS:
        for r in range(hdr + 2, hdr + 12):
            for c in range(6, 20):
                cell = ws.cell(row=r, column=c)
                cell.border    = thin
                cell.alignment = Alignment(horizontal='center', vertical='center', wrap_text=True)
                cell.font      = Font(name='ë§‘ì€ ê³ ë”•', size=9)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# UI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if not os.path.exists(DB_FILENAME):
    st.error(f"DB íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: **{DB_FILENAME}**")
    st.stop()

mode = st.radio("ğŸ“‹ ì¶”ì¶œ ëª¨ë“œ ì„ íƒ", ["ë‹¨ì¼ ë¬¼ì§ˆ ì¶”ì¶œ", "ë‹¤ì¤‘ ë¬¼ì§ˆ ì¶”ì¶œ (2ê°œ)"], horizontal=True)
st.divider()

if mode == "ë‹¨ì¼ ë¬¼ì§ˆ ì¶”ì¶œ":
    if not os.path.exists(TPL_SINGLE):
        st.error(f"í…œí”Œë¦¿ íŒŒì¼ ì—†ìŒ: **{TPL_SINGLE}**")
        st.stop()
    target_id = st.text_input("ğŸ” ë‚´ë¶€ì‹ë³„ì ì…ë ¥ (ì˜ˆ: B-3)", value="B-3")
    if st.button("ğŸš€ ì¶”ì¶œ ë° ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", key="btn_single"):
        with st.spinner("ë°ì´í„° ì¶”ì¶œ ì¤‘..."):
            try:
                df_mat = pd.read_excel(DB_FILENAME, sheet_name='ë¬¼ì§ˆì •ë³´')
                df_tox = pd.read_excel(DB_FILENAME, sheet_name='ìœ í•´ì„±ì •ë³´')
                wb     = load_workbook(TPL_SINGLE)
                extract_single(target_id.strip(), df_mat, df_tox, wb)
                buf = io.BytesIO()
                wb.save(buf)
                st.success(f"âœ… **{target_id}** ì¶”ì¶œ ì™„ë£Œ!")
                st.download_button(
                    label="ğŸ“¥ ê²°ê³¼ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
                    data=buf.getvalue(),
                    file_name=f"ì¶”ì¶œê²°ê³¼_{target_id}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

else:
    if not os.path.exists(TPL_MULTI):
        st.error(f"í…œí”Œë¦¿ íŒŒì¼ ì—†ìŒ: **{TPL_MULTI}**")
        st.stop()
    col1, col2 = st.columns(2)
    with col1:
        tid1 = st.text_input("ğŸ” ì²« ë²ˆì§¸ ë‚´ë¶€ì‹ë³„ì (ì˜ˆ: B-1)", value="B-1")
    with col2:
        tid2 = st.text_input("ğŸ” ë‘ ë²ˆì§¸ ë‚´ë¶€ì‹ë³„ì (ì˜ˆ: B-3)", value="B-3")
    if st.button("ğŸš€ ì¶”ì¶œ ë° ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", key="btn_multi"):
        if not tid1.strip() or not tid2.strip():
            st.warning("ë‘ ê°œì˜ ë‚´ë¶€ì‹ë³„ìë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif tid1.strip() == tid2.strip():
            st.warning("ì„œë¡œ ë‹¤ë¥¸ ë‚´ë¶€ì‹ë³„ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("ë°ì´í„° ì¶”ì¶œ ì¤‘..."):
                try:
                    df_mat = pd.read_excel(DB_FILENAME, sheet_name='ë¬¼ì§ˆì •ë³´')
                    df_tox = pd.read_excel(DB_FILENAME, sheet_name='ìœ í•´ì„±ì •ë³´')
                    wb     = load_workbook(TPL_MULTI)
                    extract_multi(tid1.strip(), tid2.strip(), df_mat, df_tox, wb)
                    buf = io.BytesIO()
                    wb.save(buf)
                    st.success(f"âœ… **{tid1}** + **{tid2}** ì¶”ì¶œ ì™„ë£Œ!")
                    st.download_button(
                        label="ğŸ“¥ ê²°ê³¼ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
                        data=buf.getvalue(),
                        file_name=f"ì¶”ì¶œê²°ê³¼_{tid1}_{tid2}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
